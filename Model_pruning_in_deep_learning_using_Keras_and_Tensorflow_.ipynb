{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model pruning in deep learning using Keras and Tensorflow .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNDFzDRLSfINRJ7ZuXuPCRe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akash8190/Model-pruning-in-deep-learning-using-keras-and-tensorflow/blob/main/Model_pruning_in_deep_learning_using_Keras_and_Tensorflow_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsuoqiTsVYNv",
        "outputId": "1e9aa2e4-5117-4964-c3fe-13a77da8725c"
      },
      "source": [
        " pip install -q tensorflow-model-optimization"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |██                              | 10kB 26.2MB/s eta 0:00:01\r\u001b[K     |███▉                            | 20kB 24.3MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 30kB 11.8MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 40kB 9.5MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 51kB 4.3MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 61kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 71kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 81kB 5.4MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 92kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 102kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 112kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 122kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 133kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 143kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 153kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 163kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 174kB 5.9MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwog3UrrWP0t"
      },
      "source": [
        "# model prunning using keras and tensorflow using MNIST dataset which is present in keras and see the performance after pruning and before pruning get impactaed or Not"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNcidJICWLtH",
        "outputId": "8be63bf2-42b8-4241-f40e-aa7f30007807"
      },
      "source": [
        "import tempfile\r\n",
        "import os\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "from tensorflow import keras\r\n",
        "\r\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "for5tg8CXmzu"
      },
      "source": [
        "Train a model for MNIST without pruning\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPjWeYmxXOPp",
        "outputId": "2f5e8874-002d-4d60-f7a1-5568bf8cd373"
      },
      "source": [
        "# Load MNIST dataset\r\n",
        "mnist = keras.datasets.mnist\r\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\r\n",
        "\r\n",
        "# Normalize the input image so that each pixel value is between 0 to 1.\r\n",
        "train_images = train_images / 255.0\r\n",
        "test_images = test_images / 255.0\r\n",
        "\r\n",
        "# Define the model architecture.\r\n",
        "model = keras.Sequential([\r\n",
        "  keras.layers.InputLayer(input_shape=(28, 28)),\r\n",
        "  keras.layers.Reshape(target_shape=(28, 28, 1)),\r\n",
        "  keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\r\n",
        "  keras.layers.MaxPooling2D(pool_size=(2, 2)),\r\n",
        "  keras.layers.Flatten(),\r\n",
        "  keras.layers.Dense(10)\r\n",
        "])\r\n",
        "\r\n",
        "# Train the digit classification model\r\n",
        "model.compile(optimizer='adam',\r\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "model.fit(\r\n",
        "  train_images,\r\n",
        "  train_labels,\r\n",
        "  epochs=4,\r\n",
        "  validation_split=0.1,\r\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "1688/1688 [==============================] - 17s 10ms/step - loss: 0.2994 - accuracy: 0.9149 - val_loss: 0.1143 - val_accuracy: 0.9695\n",
            "Epoch 2/4\n",
            "1688/1688 [==============================] - 17s 10ms/step - loss: 0.1151 - accuracy: 0.9666 - val_loss: 0.0767 - val_accuracy: 0.9807\n",
            "Epoch 3/4\n",
            "1688/1688 [==============================] - 16s 10ms/step - loss: 0.0819 - accuracy: 0.9760 - val_loss: 0.0665 - val_accuracy: 0.9835\n",
            "Epoch 4/4\n",
            "1688/1688 [==============================] - 16s 10ms/step - loss: 0.0671 - accuracy: 0.9801 - val_loss: 0.0613 - val_accuracy: 0.9847\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f901223def0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUAkm4xiX3FW",
        "outputId": "674f9b76-a407-4d85-9c9d-545884e99dce"
      },
      "source": [
        "_, baseline_model_accuracy = model.evaluate(\r\n",
        "    test_images, test_labels, verbose=0)\r\n",
        "\r\n",
        "print('Baseline test accuracy:', baseline_model_accuracy)\r\n",
        "\r\n",
        "_, keras_file = tempfile.mkstemp('.h5')\r\n",
        "tf.keras.models.save_model(model, keras_file, include_optimizer=False)\r\n",
        "print('Saved baseline model to:', keras_file)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline test accuracy: 0.9775999784469604\n",
            "Saved baseline model to: /tmp/tmp0gu9y51l.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPSUiGZdZftZ"
      },
      "source": [
        "# **Fine**-tune pre-trained model with pruning and see the impact on accuracy or **performance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WD4iQOu-YUE8",
        "outputId": "a55d5abb-42e2-4c0a-ac89-ce69be180630"
      },
      "source": [
        "import tensorflow_model_optimization as tfmot\r\n",
        "\r\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\r\n",
        "\r\n",
        "# Compute end step to finish pruning after 2 epochs.\r\n",
        "batch_size = 128\r\n",
        "epochs = 2\r\n",
        "\r\n",
        "validation_split = 0.1 # 10% of training set will be used for validation set. \r\n",
        "\r\n",
        "num_images = train_images.shape[0] * (1 - validation_split)\r\n",
        "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\r\n",
        "\r\n",
        "# Define model for pruning.\r\n",
        "pruning_params = {\r\n",
        "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\r\n",
        "                                                               final_sparsity=0.80,\r\n",
        "                                                               begin_step=0,\r\n",
        "                                                               end_step=end_step)\r\n",
        "}\r\n",
        "\r\n",
        "model_for_pruning = prune_low_magnitude(model, **pruning_params)\r\n",
        "\r\n",
        "# `prune_low_magnitude` requires a recompile.\r\n",
        "model_for_pruning.compile(optimizer='adam',\r\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "model_for_pruning.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "prune_low_magnitude_reshape_ (None, 28, 28, 1)         1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv2d_2 (None, 26, 26, 12)        230       \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_max_pool (None, 13, 13, 12)        1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_flatten_ (None, 2028)              1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_dense_2  (None, 10)                40572     \n",
            "=================================================================\n",
            "Total params: 40,805\n",
            "Trainable params: 20,410\n",
            "Non-trainable params: 20,395\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mORjbSg6ayo1"
      },
      "source": [
        "Train and evaluate the model against baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOqq3IlMa55i",
        "outputId": "34c66bde-d45d-43a3-d9b3-ebaf0f5bc301"
      },
      "source": [
        "logdir = tempfile.mkdtemp()\r\n",
        "\r\n",
        "callbacks = [\r\n",
        "  tfmot.sparsity.keras.UpdatePruningStep(),\r\n",
        "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\r\n",
        "]\r\n",
        "\r\n",
        "model_for_pruning.fit(train_images, train_labels,\r\n",
        "                  batch_size=batch_size, epochs=epochs, validation_split=validation_split,\r\n",
        "                  callbacks=callbacks)\r\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "  2/422 [..............................] - ETA: 23s - loss: 0.1611 - accuracy: 0.9453WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0273s vs `on_train_batch_end` time: 0.0847s). Check your callbacks.\n",
            "422/422 [==============================] - 13s 30ms/step - loss: 0.0915 - accuracy: 0.9749 - val_loss: 0.1164 - val_accuracy: 0.9708\n",
            "Epoch 2/2\n",
            "422/422 [==============================] - 12s 29ms/step - loss: 0.1205 - accuracy: 0.9676 - val_loss: 0.0845 - val_accuracy: 0.9797\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9011f96668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cv6g7Q0db8nb"
      },
      "source": [
        "## For this example, there is minimal loss in test accuracy after pruning, compared to the **baseline**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4OnSqBibAmS",
        "outputId": "c7e68cb2-77ab-4a1d-c335-dce00d686f8b"
      },
      "source": [
        "_, model_for_pruning_accuracy = model_for_pruning.evaluate(\r\n",
        "   test_images, test_labels, verbose=0)\r\n",
        "\r\n",
        "print('Baseline test accuracy:', baseline_model_accuracy) \r\n",
        "print('Pruned test accuracy:', model_for_pruning_accuracy)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline test accuracy: 0.9775999784469604\n",
            "Pruned test accuracy: 0.9690999984741211\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tELWieZergQ"
      },
      "source": [
        "# For this example, there is minimal loss in test accuracy after pruning, compared to the **baseline** model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-eMx0_Lfu8a"
      },
      "source": [
        "## so we can say that after prunning a little  diffrence in our accuracy a model is light compared to base model so we can say that pruning help to reduce the model complexity and size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPYdVD-UcHIN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}